{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k3larra/generalisation/blob/pc/shapes_XAI_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hTdz9j-fzHH"
      },
      "source": [
        "# Evaluating model generalisation on basic shapes\n",
        "This code accompanies the paper with the title \"Deep Learning, generalisation and concepts\".\n",
        "\n",
        "This code uses a number of XAI methods to produce saliency maps. Models trained on basic shapes are used and the results compared. The discussion especially addresses question on generalisation and if the trained networks generalisation can be compared to human genralisation. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Iwwa9AA2j9Rg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ1mX07G3pSU",
        "outputId": "f47a707c-da3a-40a1-db84-d529b55e8c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.0+cu116\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import shutil\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "print(torch.__version__)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # #Cleaning if needed\n",
        "# ! rm -r models\n",
        "#! rm -r generalisation\n",
        "#! rm -r testset\n",
        "# ! rm classes.txt"
      ],
      "metadata": {
        "id": "uknuOXq5p6uq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#Get testset, training information and classes\n",
        "! git clone https://github.com/k3larra/generalisation\n",
        "with ZipFile('generalisation/testset/testset.zip', 'r') as archive:\n",
        "  archive.extractall('testset')\n",
        "f = open(\"generalisation/models/models.json\")\n",
        "models = json.load(f)\n",
        "f.close()\n",
        "with open(\"generalisation/classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "num_classes = len(categories)\n",
        "\n",
        "def label_to_idx(label):\n",
        "  return categories.index(label)\n",
        "\n",
        "def idx_to_label(idx):\n",
        "  return categories[idx]"
      ],
      "metadata": {
        "id": "doyRR2dnnt-u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRw7FfUxQxqT"
      },
      "source": [
        "## Dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pBxmse55Mm4C"
      },
      "outputs": [],
      "source": [
        "# create the annotation file for the tests!\n",
        "shape_path = \"/content/testset\"\n",
        "with open(shape_path + '/shapes.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['image_location', 'label']) # Write header\n",
        "    for dirs in listdir(shape_path):\n",
        "        if(dirs.endswith(\".csv\")):\n",
        "            continue\n",
        "        for f in listdir(join(shape_path, dirs)):\n",
        "            if(join(shape_path, dirs, f).endswith(\".csv\")):\n",
        "                continue\n",
        "            elif isfile(join(shape_path, dirs, f)):\n",
        "                writer.writerow([join(dirs, f), dirs])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ1QaOGH3bdz"
      },
      "source": [
        "# XAI Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install captum \n",
        "from captum.attr import Occlusion\n",
        "from captum.attr import LayerGradCam\n",
        "from captum.attr import LayerAttribution\n",
        "from captum.attr import visualization as viz\n",
        "sign=\"positive\""
      ],
      "metadata": {
        "id": "UNxuEAKRg1Cx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_layered_gradcam(experiment_model, target_label, input_img, top_candidates, top_probs, img_index, save_path=\"\"):\n",
        "  json_data = {}\n",
        "  test_name='resnet_50' #Needs to be removed and models names from JSON be used instead.\n",
        "  input_img.requires_grad = True\n",
        "  experiment_model = experiment_model.to(device)\n",
        "  input_img = input_img.to(device)\n",
        "  if test_name == 'resnet_50':\n",
        "    layer_gradcam = LayerGradCam(experiment_model, experiment_model.layer4[2].conv3)\n",
        "  elif test_name == 'resnet_152':\n",
        "    print('resnet_152')\n",
        "    layer_gradcam = LayerGradCam(experiment_model, experiment_model.layer4[2].conv3)\n",
        "  elif test_name == 'inception_v3':\n",
        "    print('inception_v3')\n",
        "    layer_gradcam = LayerGradCam(experiment_model, experiment_model.Mixed_7c.branch_pool.conv)\n",
        "  elif test_name == 'efficientnet_b0':\n",
        "    print('efficientnet_b0')\n",
        "    layer_gradcam = LayerGradCam(experiment_model, experiment_model.features.conv)\n",
        "  else:\n",
        "    print('no layer')\n",
        "  attributions = layer_gradcam.attribute(input_img, target=target_label)\n",
        "  attributions = LayerAttribution.interpolate(attributions, input_img.shape[2:])\n",
        "  input_img = input_img.squeeze()\n",
        "  n=str(img_index)\n",
        "  if sign==\"positive\":\n",
        "    if torch.max(attributions)<0:\n",
        "      json_data[\"error\"]=\"no saliency map can be produced, only negative values in attributions\"\n",
        "    else:\n",
        "      result = viz.visualize_image_attr(attributions[0].cpu().permute(1,2,0).detach().numpy(),\n",
        "                              input_img.cpu().permute(1,2,0).detach().numpy(), \n",
        "                              method=\"blended_heat_map\",\n",
        "                              sign=sign,\n",
        "                              fig_size=(5,5))\n",
        "      result[0].savefig(save_path+n+ '_GradCam.PNG',bbox_inches='tight')\n",
        "  json_data[\"image_path\"] = save_path+n+ '_GradCam.PNG'\n",
        "  print(\"GradCam\",target_label, idx_to_label(top_candidates[0]), np.round(top_probs[0].item(),2))\n",
        "  return json_data"
      ],
      "metadata": {
        "id": "x1R9H85YEsZU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_occlusion(experiment_model, target_label, input_img, top_candidates, top_probs, img_index, save_path=\"\"):\n",
        "  json_data = {}\n",
        "  experiment_model = experiment_model.to(device)\n",
        "  input_img = input_img.to(device)\n",
        "  occlusion = Occlusion(experiment_model)\n",
        "  attributions = occlusion.attribute(input_img,\n",
        "                                  #  strides = (1, 30, 30),\n",
        "                                  #  sliding_window_shapes=(1,30,30),\n",
        "                                   strides = (3, 8, 8),\n",
        "                                   sliding_window_shapes=(3,15,15),\n",
        "                                   target=target_label,\n",
        "                                   baselines = 0)\n",
        "  input_img = input_img.squeeze()\n",
        "  n=str(img_index)\n",
        "  if sign==\"positive\":\n",
        "    if torch.max(attributions)<0:\n",
        "      json_data[\"error\"]=\"no saliency map can be produced, only negative values in attributions\"\n",
        "    else:\n",
        "      result = viz.visualize_image_attr(attributions[0].cpu().permute(1,2,0).detach().numpy(),\n",
        "                              input_img.cpu().permute(1,2,0).detach().numpy(), \n",
        "                              method=\"blended_heat_map\",\n",
        "                              sign=sign,\n",
        "                              fig_size=(5,5))\n",
        "      result[0].savefig(save_path+n+ '_Occlusion.PNG',bbox_inches='tight')\n",
        "  json_data[\"image_path\"] = save_path+n+ '_Occlusion.PNG'\n",
        "  print(\"Occlusion\",target_label, idx_to_label(top_candidates[0]), np.round(top_probs[0].item(),2))\n",
        "  return json_data"
      ],
      "metadata": {
        "id": "9brXL4IfFVbi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpers"
      ],
      "metadata": {
        "id": "2UkwY-Elo7fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here additions are needed to use tranforms native for the models\n",
        "#Image transformation\n",
        "eval_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((299, 299)),\n",
        "    ])\n",
        "\n",
        "def transform_eval_data(img_path, eval_transform = None):\n",
        "  image = Image.open(img_path).convert('RGB')\n",
        "  if eval_transform:\n",
        "      image = eval_transform(image)\n",
        "  image = image.float()\n",
        "  return image\n",
        "        "
      ],
      "metadata": {
        "id": "mr0tyVllI4O0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e6-fzCbsWSAD"
      },
      "outputs": [],
      "source": [
        "def get_all_files(experiment_path):\n",
        "  loaded_files = []\n",
        "  for f in sorted(os.listdir(experiment_path)):\n",
        "    if f.endswith('.PNG') or f.endswith('.png'):\n",
        "      loaded_files.append(f)\n",
        "  return loaded_files\n",
        "\n",
        "def load_experiment_data(experiment_path):\n",
        "  experiment_set = []\n",
        "  eval_dir = get_all_files(experiment_path)\n",
        "  eval_size = len(eval_dir)\n",
        "  for i in range(eval_size):\n",
        "    experiment_set.append(transform_eval_data(experiment_path + eval_dir[i],eval_transform))\n",
        "  return experiment_set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_input(input_img, experiment_model):\n",
        "  input_img = input_img.to(device)\n",
        "  output = experiment_model(input_img)\n",
        "  probabilities = F.softmax(output[0], dim=0)\n",
        "  top_prob, top_catid = torch.topk(probabilities, num_classes)\n",
        "  jsonData={}\n",
        "  for i in range(top_prob.size(0)):\n",
        "      prediction={}\n",
        "      prob=top_prob[i].item()\n",
        "      prediction[\"probability\"] = np.round(top_prob[i].item(),3)\n",
        "      if top_catid[i].item()<top_catid.size(0):\n",
        "        prediction[\"label\"] = idx_to_label(top_catid[i])\n",
        "        prediction[\"labelid\"] = top_catid[i].item()\n",
        "      jsonData[i]=prediction\n",
        "  return top_catid, top_prob, jsonData"
      ],
      "metadata": {
        "id": "lEiMiIwD7PtN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Study\n"
      ],
      "metadata": {
        "id": "Xj3R8OQRux-U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_dpfLJCvWbtZ"
      },
      "outputs": [],
      "source": [
        "def run_experiment_shapes(experiment_model, experiment_path, save_path, experiment_name, label_id=0):\n",
        "  experiment_set = load_experiment_data(os.path.join(experiment_path, ''))\n",
        "  #print(\"------------------\")\n",
        "  path_to_save = os.path.join(save_path + experiment_name, '')\n",
        "  if not os.path.exists(path_to_save):\n",
        "    os.makedirs(path_to_save)\n",
        "  json_data = {}\n",
        "  json_data[\"title\"]=(experiment_name.split('/'))[2]\n",
        "  json_data[\"unixtime\"] = time.time()\n",
        "  json_data[\"datetime\"] = time.asctime( time.localtime(time.time()))\n",
        "  json_data[\"description\"] = \"To be added\"\n",
        "  json_data[\"testset\"] = \"https://github.com/k3larra/generalisation/tree/pc/testset\"\n",
        "  for idx, experiment_sample in enumerate(experiment_set):\n",
        "    plt.axis(\"off\")\n",
        "    plt.imsave(path_to_save+str(idx)+ '_Transfomed.PNG',experiment_sample.cpu().permute(1,2,0).detach().numpy())\n",
        "    plt.imshow(experiment_sample.permute(1,2,0))\n",
        "    experiment_sample = experiment_sample.unsqueeze(0)\n",
        "    top_candidates, top_probs, jdata = process_input(experiment_sample, experiment_model)\n",
        "    json_data[idx] = jdata\n",
        "    json_data[idx][\"gradcam\"] = calculate_layered_gradcam(experiment_model, \n",
        "                     target_label=top_candidates[label_id].item(),\n",
        "                     input_img=experiment_sample,\n",
        "                     top_candidates=top_candidates, top_probs=top_probs,\n",
        "                     img_index=idx, save_path=path_to_save)\n",
        "    \n",
        "    json_data[idx][\"occlusion\"] = calculate_occlusion(experiment_model, \n",
        "                            target_label=top_candidates[label_id],\n",
        "                            input_img=experiment_sample,\n",
        "                            top_candidates=top_candidates, top_probs=top_probs,\n",
        "                            img_index=idx, save_path=path_to_save) \n",
        "    j_data = {} \n",
        "    j_data[\"image_path\"] = path_to_save+str(idx)+ '_Transfomed.PNG'    \n",
        "    json_data[idx][\"transformed\"] = j_data\n",
        "  return json_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments!"
      ],
      "metadata": {
        "id": "IVA57u4-JLqg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lZTmAjSYakt"
      },
      "outputs": [],
      "source": [
        "#%%capture\n",
        "models_path= \"generalisation/models/\"\n",
        "save_path = 'models/'\n",
        "testset_path = \"testset/\"\n",
        "#Get models\n",
        "trained_models=[]\n",
        "ids = []\n",
        "for id in models:\n",
        "  d = join(models_path, id+\"_complete_model.pth\")\n",
        "  if (isfile(d)):\n",
        "    trained_models.append(d)\n",
        "    ids.append(id)\n",
        "#Get study folders\n",
        "study_directories=[]\n",
        "for name in os.listdir(testset_path):\n",
        "    d = os.path.join(testset_path, name)\n",
        "    if os.path.isdir(d):\n",
        "      study_directories.append(name)\n",
        "study_directories.sort()\n",
        "#Ok run\n",
        "for trained_model,id in zip(trained_models,ids):\n",
        "  json_study = {}\n",
        "  for testset_folder in study_directories:\n",
        "    print(trained_model,\":\",id,\":\",testset_folder)\n",
        "    model_ft= torch.load(trained_model, map_location=torch.device(device))\n",
        "    model_ft.eval()\n",
        "    model_ft = model_ft.to(device)\n",
        "    json_study[testset_folder] = run_experiment_shapes(model_ft, testset_path+testset_folder, save_path, id+'/studies/'+testset_folder,  0)\n",
        "  models[id]['studies'] = json_study\n",
        "with open(save_path + 'models.json', 'w') as outfile:\n",
        "  outfile.write(json.dumps(models))    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_name = \"saliency_maps\"\n",
        "shutil.make_archive(zip_name, 'zip', \"models\")"
      ],
      "metadata": {
        "id": "veKbsDa_Jsd4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}